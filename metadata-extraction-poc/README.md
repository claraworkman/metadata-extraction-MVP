# Metadata Extraction POC

Extract contract metadata directly from multilingual contracts (Swedish, Polish, Estonian, Norwegian, Danish, Latvian, Lithuanian) without translation.

## üéØ What This Does

- Reads contracts from **Azure Blob Storage** or local files
- Supports `.txt`, `.docx`, or `.pdf` formats (with markdown structure preservation)
- Extracts 12 Sirion metadata fields using **gpt-5-mini**
- **Concurrent processing**: 3-5x faster with 3 parallel workers
- **Smart hybrid approach**: Auto-retries low-confidence results with translation
- **Markdown extraction**: PDFs preserve tables, headings, and structure
- Outputs structured CSV ready for Sirion.ai import
- Processes contracts in original language, returns English metadata
- No translation step needed (98% cost savings)

## ‚ö° Performance

- **Sequential Mode**: ~8-10 seconds for 4 contracts
- **Concurrent Mode (3 workers)**: ~3-4 seconds for 4 contracts
- **3-5x faster** for large batches with parallel processing
- **Cost**: Same per contract (concurrency doesn't increase API calls)
- **Smart retry**: Auto-translates low-confidence results for better accuracy

## üéØ Accuracy Features

### Hybrid Extraction Strategy
1. **Single-call extraction** (default): Direct multilingual processing - fast & accurate
2. **Field validation**: Automatically checks for missing critical fields:
   - Customer (CK) Entity
   - Supplier Entity
   - Effective Date
   - Contract Type
3. **Smart auto-retry**: If LOW confidence OR missing critical fields, automatically:
   - Translates contract to English
   - Re-extracts metadata from translation
   - Uses improved result if better

### Few-Shot Learning
- Enhanced prompts with 3 example contracts (Swedish, Polish, Estonian)
- Shows GPT correct entity extraction patterns per language
- Emphasizes: "NEVER leave Customer or Supplier entities empty"

### PDF Processing
- Uses **Document Intelligence prebuilt-layout** model
- **Markdown output format** preserves:
  - Tables as markdown tables
  - Headings with proper structure
  - Lists and formatting
  - Better context for GPT extraction

## üìã Requirements

- Python 3.8+
- Azure OpenAI access (gpt-5-mini deployment)
- Azure Blob Storage account (for cloud storage)
- Azure Document Intelligence (for PDF OCR)
- Azure CLI installed and authenticated (`az login`)

## üöÄ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Azure Services
Edit `.env` file with your Azure endpoints:
```ini
AZURE_OPENAI_ENDPOINT=https://your-openai-endpoint.cognitiveservices.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-5-mini
DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-doc-intel-endpoint.cognitiveservices.azure.com/
STORAGE_ACCOUNT_NAME=yourstorageaccount

# Optional: Parallel processing configuration
MAX_WORKERS=10        # Concurrent workers (default: 10)
MAX_RETRIES=3         # Retry attempts per file (default: 3)
RETRY_DELAY=2         # Seconds between retries (default: 2)
```

**Parallel Processing Settings**:
- `MAX_WORKERS=10`: Process 10 files simultaneously (adjust based on rate limits)
- `MAX_RETRIES=3`: Retry failed files up to 3 times with exponential backoff
- `RETRY_DELAY=2`: Initial delay between retries (doubles each attempt)

### 3. Login to Azure
```bash
az login
```

### 4. Run the Script
```bash
python metadata-extraction-POC.py
```

When prompted:
1. **Select source**: 
   - `1` for Azure Blob Storage (recommended)
   - `2` for local folder
2. **Container/Folder**: Enter container name or folder path
3. **Output CSV**: Enter filename (or press Enter for default)

## üì¶ Azure Blob Storage Mode (Recommended)

### Upload Contracts to Blob Storage
```bash
# Using Azure CLI
az storage blob upload-batch \
  --account-name stcirclektranslation \
  --destination documents \
  --source ./contracts/ \
  --auth-mode login
```

### Run Extraction
```bash
python metadata-extraction-POC.py

Select source:
  1. Azure Blob Storage (recommended)
  2. Local folder
Enter choice: 1

Enter Azure Blob Storage container name: documents
Enter output CSV name: sirion_metadata.csv
```

The script will:
- Connect to Azure Blob Storage
- List all .txt, .docx, .pdf files
- Download and process each file
- Extract metadata directly
- Create CSV output

## üíª Local Folder Mode

For testing or small batches:
```bash
python metadata-extraction-POC.py

Select source:
  1. Azure Blob Storage (recommended)
  2. Local folder
Enter choice: 2

Enter folder path: sample_contracts
Enter output CSV name: test.csv
```

## üìä Output

The script creates a CSV file with:
- File name
- Source language detected
- 12 Sirion metadata fields (in English)
- Confidence score (high/medium/low)
- Extraction notes

### Fields Extracted:
1. Customer (CK) Entity
2. Supplier Entity
3. Effective Date
4. Expiration Date
5. Term Type
6. Governing Law
7. Contract Type
8. Contract Currency
9. Payment Term
10. Termination for Convenience
11. Notice Period for Termination for Convenience
12. Party with the Right to Terminate for Convenience

## üí∞ Cost

- **~$0.0014 per contract** (using GPT-5-mini)
- **1,000 contracts ‚âà $1.40**
- **10,000 contracts ‚âà $14**
- ~5x cheaper than gpt-5.1 with equal accuracy

## üîÑ Model Options

**GPT-5-mini (current)**:
- Cost: $0.69/M tokens (~$0.0014/contract)
- Accuracy: 100% field extraction on test set
- Best for: Production use with cost optimization

**GPT-5.1 (alternative)**:
- Cost: $3.44/M tokens (~$0.007/contract)
- Accuracy: 100% field extraction on test set
- Best for: Maximum reasoning capability
- To switch: Update `AZURE_OPENAI_DEPLOYMENT=gpt-5.1` in `.env`

## ‚è±Ô∏è Speed

- **.txt files**: 1-2 seconds each
- **.docx files**: 2-3 seconds each
- **.pdf files**: 5-10 seconds each (OCR)

## üåç Supported Languages

- Swedish (sv)
- Norwegian (no)
- Danish (da)
- Polish (pl)
- Latvian (lv)
- Lithuanian (lt)
- Estonian (et)

## üìÅ File Structure

```
metadata-extraction-poc/
‚îú‚îÄ‚îÄ metadata-extraction-POC.py    # Main script
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ .env                          # Azure configuration
‚îî‚îÄ‚îÄ README.md                     # This file
```

## üîß Advanced Usage

### Test Single Contract
```bash
python metadata-extraction-POC.py "path/to/contract.txt"
```

### Process Specific Folder
```bash
python metadata-extraction-POC.py
# Enter: C:\Contracts\Batch1
# Enter: batch1_output.csv
```

## ‚ö†Ô∏è Troubleshooting

**"Authentication failed"**
- Run `az login` to refresh credentials

**"Module not found"**
- Run `pip install -r requirements.txt`

**"Folder not found"**
- Check folder path exists and has read permissions

**PDF returns blank**
- Ensure PDF has selectable text (not just scanned image)

## ‚úÖ Next Steps

1. Review generated CSV in Excel
2. Check contracts with "medium" or "low" confidence
3. Verify company names and dates
4. Import to Sirion.ai CLM platform

## üìû Support

For issues or questions about this POC, contact the AI team.
